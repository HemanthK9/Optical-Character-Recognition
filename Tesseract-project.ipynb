{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer this website for detailed explanation\n",
    "- https://www.pyimagesearch.com/2018/09/17/opencv-ocr-and-text-recognition-with-tesseract/\n",
    "- https://www.pyimagesearch.com/2018/08/20/opencv-text-detection-east-text-detector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "#Set path to wherever Tesseract-OCR is installed\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(scores, geometry):\n",
    "    # Grab number of rows and columns from the scores volume, then initialize our set of bounding box rectangles \n",
    "    # and corresponding confidence scores\n",
    "    (nRows, nCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "    \n",
    "    # Loop over the number of rows\n",
    "    for y in range(0, nRows):\n",
    "        # Extract scores (probabilities) followed by the geometrical data used to derive potential bounding box\n",
    "        # coordinates that surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "        \n",
    "        # Loop over the number of columns\n",
    "        for x in range(0, nCols):\n",
    "            \n",
    "            #If our score doesn't have sufficient probability, ignore it\n",
    "            if scoresData[x] < min_confidence:\n",
    "                continue\n",
    "                \n",
    "            # Compute the offset factor as our resulting feature maps will be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "            \n",
    "            # Extract the rotation angle for the prediction and compute its sine and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            \n",
    "            # Use the geometry data to derive height and width of the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "            \n",
    "            # Compute both the starting and ending (x, y)-coordinates for the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "            \n",
    "            # Add the bounding box coordinates and probabilities to the respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "            \n",
    "    # Return a tuple of the bounding boxes and the associated confidences\n",
    "    return (rects, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the path to the image\n",
    "image_path = 'test2.png'\n",
    "\n",
    "#This is the path to the frozen_east_text_detector.pb file that OpenCV provides\n",
    "east_path = 'opencv-text-recognition/frozen_east_text_detection.pb'\n",
    "\n",
    "#Other optional command line arguments\n",
    "min_confidence = 0.5\n",
    "width = 320\n",
    "height = 320\n",
    "padding = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the image and grab its dimensions\n",
    "image = cv2.imread(image_path)\n",
    "original = image.copy()\n",
    "(original_height, original_width) = original.shape[:2]\n",
    "\n",
    "#Set the new width and height and then determine the ratio between the old and new dimensions\n",
    "new_width = width\n",
    "new_height = height\n",
    "ratio_width = original_width / new_width\n",
    "ratio_height = original_height / new_height\n",
    "\n",
    "#resize the image and grab the new dimensions\n",
    "image = cv2.resize(image, (new_width, new_height))\n",
    "(height, width) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_height, original_width)\n",
    "print(height, width)\n",
    "print(ratio_height, ratio_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Setting Up the EAST Detector\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EAST Detector\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Define the two output layer names for the EAST detector model that we are interested in\n",
    " - the first is the output probabilities\n",
    " - the second can be used to derive the bounding box coordinates of text\n",
    "'''\n",
    "\n",
    "layerNames = [\n",
    "    \"feature_fusion/Conv_7/Sigmoid\",\n",
    "    \"feature_fusion/concat_3\"\n",
    "]\n",
    "\n",
    "#Load the pretrained EAST detector\n",
    "print(\"Loading EAST Detector\")\n",
    "net = cv2.dnn.readNet(east_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HEMANTH KUMAR\\.conda\\envs\\mlproject\\lib\\site-packages\\imutils\\object_detection.py:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "  overlap = (w * h) / area[idxs[:last]]\n",
      "C:\\Users\\HEMANTH KUMAR\\.conda\\envs\\mlproject\\lib\\site-packages\\imutils\\object_detection.py:62: RuntimeWarning: invalid value encountered in greater\n",
      "  np.where(overlap > overlapThresh)[0])))\n"
     ]
    }
   ],
   "source": [
    "# Construct a blob from the image and then perform a forward pass of the model to obtain the two output layer sets\n",
    "blob = cv2.dnn.blobFromImage(image,\n",
    "                             1.0,\n",
    "                             (width, height),\n",
    "                             (123.68, 116.78, 103.94),\n",
    "                             swapRB = True,\n",
    "                             crop = False)\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "\n",
    "# Decode the predictions, then apply non-maxima-suppression to suppress weak, overlapping bounded boxes\n",
    "(rects, confidences) = decode_predictions(scores, geometry)\n",
    "boxes = non_max_suppression(np.array(rects), probs = confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1, 80, 80), (1, 5, 80, 80))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape, geometry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([293, 198, 260, 200])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "181\n"
     ]
    }
   ],
   "source": [
    "print(len(rects))\n",
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma y\n",
      "i e\n",
      "_— FJ\n",
      "_—\n",
      "a a\n",
      "tt ~\n",
      "—\n",
      "—_—.\n",
      "663 201 580 201\n",
      "ta |\n",
      "rr\n",
      "—\n",
      "a\n",
      "Be\n",
      "- ia\n",
      "ta iz\n",
      "1066 190 983 192\n",
      "659 202 576 206\n",
      "Ww wW\n",
      "Oo\n",
      "618 203 584 207\n",
      "ee\n",
      "oe\n",
      "587 202 587 193\n",
      "a\n",
      "4\n",
      "rr rs\n",
      "889 190 968 184\n",
      "580 199 584 196\n",
      "re\n",
      "|\n",
      "1036 192 979 199\n",
      "ar rr\n",
      "565 205 584 189\n",
      "889 185 957 185\n",
      "1055 188 979 197\n",
      "Be\n",
      "572 199 576 201\n",
      "614 203 576 212\n",
      "_\n",
      "ne\n",
      "655 203 572 212\n",
      "a\n",
      "561 202 576 192\n",
      "_\n",
      "482 165 520 208\n",
      "979 189 983 183\n",
      "1006 191 976 193\n",
      "523 165 523 208\n",
      "—\n",
      "908 187 957 187\n",
      "531 206 591 189\n",
      "ee\n",
      "—_\n",
      "572 208 595 187\n",
      "569 199 572 206\n",
      "919 190 964 184\n",
      "535 207 595 186\n",
      "550 204 572 198\n",
      "501 212 595 193\n",
      "964 187 972 187\n",
      "674 189 569 195\n",
      "1043 189 979 193\n",
      "565 173 531 210\n",
      "569 179 542 213\n",
      "610 202 569 217\n",
      "994 193 976 198\n",
      "535 174 531 212\n",
      "—_\n",
      "\n",
      "508 210 599 189\n",
      "859 190 972 183\n",
      "866 194 991 182\n",
      "953 189 968 184\n",
      "520 205 580 194\n",
      "569 185 554 215\n",
      "900 196 983 183\n",
      "942 189 964 188\n",
      "565 192 561 216\n",
      "-\n",
      "927 195 979 182\n",
      "550 205 565 204\n",
      "610 198 561 219\n",
      "re\n",
      "538 179 538 214\n",
      "508 181 546 215\n",
      "610 190 550 217\n",
      "859 187 953 186\n",
      "606 184 538 215\n",
      "968 196 983 183\n",
      "976 199 991 180\n",
      "550 197 554 215\n",
      "610 179 535 212\n",
      "535 213 599 186\n",
      "505 208 603 184\n",
      "478 208 603 192\n",
      "467 201 561 196\n",
      "471 206 584 194\n",
      "7\n",
      "870 200 1002 180\n",
      "1104 190 979 192\n",
      "927 204 991 182\n",
      "987 196 972 204\n",
      "836 191 991 181\n",
      "1021 192 976 204\n",
      "979 190 976 193\n",
      "—\n",
      "927 188 957 192\n",
      "493 204 572 192\n",
      "wy Wa\n",
      "_\n",
      "440 216 606 188\n",
      "=\n",
      "478 209 603 188\n",
      "463 214 606 186\n",
      "=\n",
      "840 197 1002 181\n",
      "651 201 554 219\n",
      "=\n",
      "655 204 565 217\n",
      "WwW WW\n",
      "908 185 945 190\n",
      "478 203 557 201\n",
      "904 201 983 182\n",
      "__\n",
      "493 201 557 196\n",
      "689 190 569 195\n",
      "444 209 599 189\n",
      "1047 189 976 203\n",
      "667 188 565 201\n",
      "523 162 512 208\n",
      "651 192 546 217\n",
      "501 204 561 202\n",
      "968 195 972 200\n",
      "832 187 976 182\n",
      "512 201 569 196\n",
      "—_\n",
      "J\n",
      "1092 189 976 197\n",
      "569 167 527 209\n",
      "576 210 595 185\n",
      "\n",
      "1013 193 972 208\n",
      "1002 190 964 210\n",
      "448 205 584 198\n",
      "961 205 1006 179\n",
      "994 185 957 210\n",
      "\n",
      "444 211 595 197\n",
      "422 174 542 215\n",
      "682 185 569 199\n",
      "Bn\n",
      "697 189 565 189\n",
      "651 183 538 215\n",
      "976 201 964 209\n",
      "742 173 806 208\n",
      "991 182 953 210\n",
      "603 170 527 210\n",
      "\n",
      ":\n",
      "1040 189 972 208\n",
      "ta ta\n",
      "983 178 945 208\n",
      "957 203 964 206\n",
      "_lhlhCkG (.f, zz\n",
      "1092 190 979 203\n",
      "968 201 957 213\n",
      "a\n",
      "667 192 561 207\n",
      "648 178 531 212\n",
      "nn\n",
      "881 205 1013 180\n",
      "1032 187 968 210\n",
      "961 197 949 213\n",
      "re\n",
      "\n",
      "ww Ww\n",
      "WW\n",
      "-- ea\n",
      "1021 183 961 210\n",
      "422 219 599 191\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list of results\n",
    "results = []\n",
    "\n",
    "# Loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    # Scale the bounding box coordinates based on the respective ratios\n",
    "    startX = int(startX * ratio_width)\n",
    "    startY = int(startY * ratio_height)\n",
    "    endX = int(endX * ratio_width)\n",
    "    endY = int(endY * ratio_height)\n",
    "    \n",
    "    # In order to obtain a better result at OCR, we can apply a bit of padding to our bounding box, so it can encompass \n",
    "    # the whole text area, in case it already doesn't\n",
    "    deltaX = int((endX - startX) * padding)\n",
    "    deltaY = int((endY - startY) * padding)\n",
    "    \n",
    "    # Apply padding to each side of the bounding box respectively. Also ensure it doesn't cross image boundaries\n",
    "    startX = max(0, startX - deltaX)\n",
    "    startY = max(0, startY - deltaY)\n",
    "    endX = min(original_width, endX + (deltaX*2))\n",
    "    endY = min(original_height, endY + (deltaY*2))\n",
    "    \n",
    "    # Extract the actual padded Region Of Interest (ROI)\n",
    "    roi = original[endY:startY, endX:startX]\n",
    "    \n",
    "    try:\n",
    "        # in order to apply Tesseract v4 to OCR text we must supply (1) a language, (2) an OEM flag of 4, indicating that the \n",
    "        # we wish to use the LSTM neural net model for OCR, and finally (3) an OEM value, in this case, 7 which implies\n",
    "        # that we are treating the ROI as a single line of text\n",
    "        config = (\"-l eng --oem 1 --psm 7\")\n",
    "        text = pytesseract.image_to_string(roi, config=config)\n",
    "        print(text)\n",
    "        # Add the bounding box coordinates and the OCR'd text to the list of results\n",
    "        results.append(((startX, startY, endX, endY), text))\n",
    "    except:\n",
    "        print(startX, startY, endX, endY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR TEXT\n",
      "========\n",
      "\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "ta ta\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "nn\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "Oo\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "re\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "Be\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "Bn\n",
      "\n",
      "OCR TEXT\n",
      "========\n",
      "rr rs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort the results bounding box coordinates from top to bottom\n",
    "results = sorted(results, key=lambda r:r[0][1])\n",
    " \n",
    "# loop over the results\n",
    "for ((startX, startY, endX, endY), text) in results:\n",
    "    # display the text OCR'd by Tesseract\n",
    "    print(\"OCR TEXT\")\n",
    "    print(\"========\")\n",
    "    print(\"{}\\n\".format(text))\n",
    "\n",
    "    # strip out non-ASCII text so we can draw the text on the image\n",
    "    # using OpenCV, then draw the text and a bounding box surrounding\n",
    "    # the text region of the input image\n",
    "    text = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "    output = original.copy()\n",
    "    cv2.rectangle(output, (startX, startY), (endX, endY),\n",
    "        (0, 0, 255), 2)\n",
    "    cv2.putText(output, text, (startX, startY - 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "    # show the output image\n",
    "    cv2.imshow(\"Text Detection\", output)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
